{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "source_code_prunning_quantization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L0taMc8GziPa"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-VNxBDbxXPd"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWSRY6P8-XBA"
      },
      "source": [
        "!pip3 install pytorch2keras\n",
        "!pip install scipy\n",
        "!pip install imgaug==0.2.6\n",
        "!pip install -q keras\n",
        "!pip install -q tqdm\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "!pip install -q tensorflow-model-optimization\n",
        "!apt-get -qq install xxd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7NHnqx--Fvj"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot1w7RlwaEIJ"
      },
      "source": [
        "# PYTORCH\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn.utils.prune as prune\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets, models\n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# KERAS\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.models import Model\n",
        "# force a channel ordering\n",
        "from keras import backend\n",
        "# force channels-first ordering\n",
        "backend.set_image_data_format('channels_first')\n",
        "import tensorflow as tf\n",
        "tf.executing_eagerly()\n",
        "import tensorflow as tf\n",
        "import tensorflow_model_optimization as tfmot\n",
        "from keras import backend as K\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# GERAL\n",
        "from pytorch2keras.converter import pytorch_to_keras\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6zww49l-JHO"
      },
      "source": [
        "# Preparação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvbVtHHfI6nw"
      },
      "source": [
        "O dataset deve estar em formato zip no google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze6uNcoHn-XT",
        "outputId": "79c77bd0-3312-462b-df12-091e1343c6e5"
      },
      "source": [
        "# monta o google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upA9Rss5MtVM"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/chest_xray.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_16C3Qay1KTd"
      },
      "source": [
        "!rm -rf /content/chest_xray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xPogV_G-TCl"
      },
      "source": [
        "# Funções"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdWG6pfWa-k0"
      },
      "source": [
        "def print_size_of__torch_model(model):\n",
        "  torch.save(model.state_dict(), \"temp.p\")\n",
        "  print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "  os.remove('temp.p')\n",
        "\n",
        "def print_size_of_keras_model(model):\n",
        "  model.save(\"temp.p\")\n",
        "  print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "  os.remove('temp.p')\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "\n",
        "def prepararDados(input_size):\n",
        "  datadir = '/content/chest_xray'\n",
        "  traindir = datadir + '/train/'\n",
        "  validdir = datadir + '/val/'\n",
        "  testdir = datadir + '/test/'\n",
        " \n",
        "  batch_size = 32\n",
        "\n",
        "  image_transforms = {\n",
        "    'train': transforms.Compose([    \n",
        "        transforms.Resize((input_size,input_size)),        \n",
        "        transforms.RandomHorizontalFlip(), \n",
        "        transforms.RandomResizedCrop((input_size,input_size)),  \n",
        "        transforms.ToTensor(), \n",
        "      ]),\n",
        "\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),      \n",
        "        transforms.ToTensor(),\n",
        "            ]),\n",
        "\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((input_size,input_size)),   \n",
        "        transforms.ToTensor(),\n",
        "            ])\n",
        "  }\n",
        "  \n",
        "  # Datasets\n",
        "  data = {\n",
        "    'train':\n",
        "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
        "    'val':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['val']),\n",
        "    'test':\n",
        "    datasets.ImageFolder(root=testdir, transform=image_transforms['test'])\n",
        "  } \n",
        "\n",
        "\n",
        "  dataloaders = {\n",
        "      'train': DataLoader(data['train'], shuffle=True, batch_size=batch_size, num_workers=0),\n",
        "      'val': DataLoader(data['val'], batch_size=batch_size, shuffle=True),\n",
        "      'test': DataLoader(data['test'], batch_size=batch_size, shuffle=True)\n",
        "  }\n",
        "  return dataloaders\n",
        "\n",
        "\n",
        "def preparaDadosKeras(input_size=224, bs=32):\n",
        "  train_datagen = ImageDataGenerator(horizontal_flip=True, data_format=\"channels_first\", rescale=1/255)\n",
        "  \n",
        "  test_datagen = ImageDataGenerator(data_format=\"channels_first\", rescale=1/255)\n",
        "\n",
        "  train_datagen = train_datagen.flow_from_directory('/content/chest_xray/train', target_size=(input_size, input_size), shuffle=True, interpolation='bilinear', batch_size=bs, class_mode='sparse')\n",
        "\n",
        "  test_datagen = test_datagen.flow_from_directory('/content/chest_xray/test', target_size=(input_size, input_size), shuffle=True, interpolation='bilinear', batch_size=bs, class_mode='sparse')\n",
        "  \n",
        "  data_generators = {\n",
        "      'train': train_datagen,\n",
        "      'val': test_datagen,\n",
        "      'test': test_datagen\n",
        "  }\n",
        "  return data_generators\n",
        "        \n",
        "def carregar_resnet():\n",
        "  resnet, input_size = initialize_model('resnet', 2, True, use_pretrained=True)\n",
        "  resnet.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/Resnet18/resnet.acc'))\n",
        "  return resnet, input_size\n",
        "\n",
        "def carregar_densenet():\n",
        "  densenet, input_size = initialize_model('densenet', 2, True, use_pretrained=True)\n",
        "  densenet.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/Densenet121/densenet.acc'))\n",
        "  return densenet, input_size\n",
        "\n",
        "def carregar_alexnet():\n",
        "  alexnet, input_size = initialize_model('alexnet', 2, True, use_pretrained=True)\n",
        "  alexnet.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/AlexNet/alexnet.acc'))\n",
        "  return alexnet, input_size\n",
        "\n",
        "def carregar_googlenet():\n",
        "  googlenet, input_size = initialize_model('googlenet', 2, True, use_pretrained=True)\n",
        "  googlenet.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/GoogLeNet/googlenet.acc'))\n",
        "  return googlenet, input_size\n",
        "\n",
        "def carregar_inception():\n",
        "  inception, input_size = initialize_model('inception', 2, True, use_pretrained=True)\n",
        "  inception.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/Inception V3/inception.acc'))\n",
        "  return inception, input_size\n",
        "\n",
        "def carregar_vgg():\n",
        "  vgg = models.vgg19_bn(pretrained=True)\n",
        "  num_ftrs = vgg.classifier[6].in_features\n",
        "  vgg.classifier[6] = nn.Linear(num_ftrs, 2)\n",
        "  vgg.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/VGG/vgg.acc'))\n",
        "  return vgg, 224\n",
        "\n",
        "def carregar_cnn(model_save_name):\n",
        "    model = Network()    \n",
        "    model.load_state_dict(torch.load(model_save_name))\n",
        "    return model\n",
        "\n",
        "def carregar_ensemble():\n",
        "  #load the models\n",
        "  resnet, input_size = carregar_resnet()\n",
        "  vgg, input_size = carregar_vgg()\n",
        "  densenet, input_size = carregar_densenet()\n",
        "  alexnet, input_size = carregar_alexnet()\n",
        "  googlenet, input_size = carregar_googlenet()\n",
        "  ensemble = {'resnet': resnet, 'vgg': vgg, 'densenet': densenet, 'alexnet': alexnet, 'googlenet': googlenet}\n",
        "  return ensemble\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "  if feature_extracting:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "  # Initialize these variables which will be set in this if statement. Each of these\n",
        "  \n",
        "  #   variables is model specific.\n",
        "  model_ft = None\n",
        "  input_size = 0\n",
        "\n",
        "  if model_name == \"resnet\":\n",
        "    \"\"\" Resnet18\n",
        "    \"\"\"\n",
        "    model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    set_parameter_requires_grad(model_ft.layer4, True)\n",
        "    \n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "  elif model_name == \"alexnet\":\n",
        "    \"\"\" Alexnet\n",
        "    \"\"\"\n",
        "    model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft.features, feature_extract)\n",
        "    num_ftrs = model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "  elif model_name == \"vgg\":\n",
        "    \"\"\" VGG11_bn\n",
        "    \"\"\"\n",
        "    model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.classifier[6].in_features\n",
        "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "  elif model_name == \"squeezenet\":\n",
        "    \"\"\" Squeezenet\n",
        "    \"\"\"\n",
        "    model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft.features, feature_extract)\n",
        "    model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "    model_ft.num_classes = num_classes\n",
        "    input_size = 224\n",
        "\n",
        "  elif model_name == \"densenet\":\n",
        "    \"\"\" Densenet\n",
        "    \"\"\"\n",
        "    model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.classifier.in_features\n",
        "    model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "  elif model_name == \"inception\":\n",
        "    \"\"\" Inception v3\n",
        "    Be careful, expects (299,299) sized images and has auxiliary output\n",
        "    \"\"\"\n",
        "    model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    # Handle the auxilary net\n",
        "    num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "    model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    # Handle the primary net\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "    input_size = 299\n",
        "\n",
        "  elif model_name == \"googlenet\":\n",
        "    \"\"\" GoogLeNet\n",
        "    \"\"\"\n",
        "    model_ft = models.googlenet(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "\n",
        "  else:\n",
        "      print(\"Invalid model name, exiting...\")\n",
        "      exit()\n",
        "\n",
        "  return model_ft, input_size\n",
        "\n",
        "def testePruning(model, data_loader):\n",
        "  if (torch.cuda.is_available()):\n",
        "    model = model.cuda()\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_correct = 0\n",
        "  tot_predictions = []\n",
        "  labels = []\n",
        "  for batch in data_loader:\n",
        "    data , target = batch\n",
        "    if torch.cuda.is_available():\n",
        "      data,target = data.cuda(),target.cuda()    \n",
        "    output = model(data)\n",
        "    loss = F.cross_entropy(output,target)\n",
        "    running_loss += loss.item()\n",
        "    preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "    running_correct += preds.eq(target.data.view_as(preds)).cpu().sum().item()\n",
        "    tot_predictions.extend(preds.data.cpu().numpy())\n",
        "    labels.extend(target.data.cpu().numpy())\n",
        "  loss = running_loss/len(data_loader.dataset)\n",
        "  accuracy = 100. * running_correct/len(data_loader.dataset)  \n",
        "  return accuracy, loss\n",
        "\n",
        "def carrega_model(name):\n",
        "  model = None\n",
        "  if name == 'Resnet18':\n",
        "    model, input_size = carregar_resnet()\n",
        "  elif name == 'VGG':\n",
        "    model, input_size = carregar_vgg()\n",
        "  elif name == 'Densenet121': \n",
        "    model, input_size = carregar_densenet()\n",
        "  elif name == 'AlexNet': \n",
        "    model, input_size = carregar_alexnet()\n",
        "  elif name == 'GoogLeNet':\n",
        "    model, input_size = carregar_googlenet()\n",
        "  elif name == 'Aluno':\n",
        "    model = carregar_cnn('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno_kd_v2.acc')\n",
        "  return model \n",
        "\n",
        "def calcSTD(model_name):\n",
        "  model = carrega_model(model_name) \n",
        "  \n",
        "  #calc Media\n",
        "  media = 0.0\n",
        "  n = 0\n",
        "  # For each layer except the output one\n",
        "  for layer in model.modules(): \n",
        "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "      array = layer.weight.detach().numpy()\n",
        "      media += np.mean(array)\n",
        "      n += 1\n",
        "  media = (media/n)\n",
        "\n",
        "  # Calc std\n",
        "  n = 0\n",
        "  std = 0.0\n",
        "  sum = 0 \n",
        "  for layer in model.modules(): \n",
        "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "      array = layer.weight.detach().numpy()\n",
        "      n += array.size\n",
        "      sub = array - media\n",
        "      pot = sub**2\n",
        "      sum += np.sum(pot)\n",
        "  sum = sum/(n-1)\n",
        "  std = sum**0.5\n",
        "  return std\n",
        "  \n",
        "def carrega_model_prunned(name):\n",
        "  model = None\n",
        "  if name == 'Resnet18':\n",
        "    model, input_size = initialize_model('resnet', 2, True, use_pretrained=True)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/Resnet18/resnet18-prunned.acc'))\n",
        "  elif name == 'VGG':\n",
        "    model = models.vgg19_bn(pretrained=True)\n",
        "    num_ftrs = model.classifier[6].in_features\n",
        "    model.classifier[6] = nn.Linear(num_ftrs, 2)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/VGG/vgg-prunned.acc'))\n",
        "  elif name == 'Densenet121': \n",
        "    model, input_size = initialize_model('densenet', 2, True, use_pretrained=True)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/Densenet121/densenet121-prunned.acc'))\n",
        "  elif name == 'AlexNet': \n",
        "    model, input_size = initialize_model('alexnet', 2, True, use_pretrained=True)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/AlexNet/alexnet-prunned.acc'))\n",
        "  elif name == 'GoogLeNet':\n",
        "    model, input_size = initialize_model('googlenet', 2, True, use_pretrained=True)\n",
        "    model.load_state_dict(torch.load('/content/drive/My Drive/Modelos Salvos/GoogLeNet/googlenet-prunned.acc'))\n",
        "  elif name == 'Aluno':\n",
        "    model = carregar_cnn('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned.acc')\n",
        "  return model \n",
        "\n",
        "def carrega_model_prunned_keras(name):\n",
        "  model = None\n",
        "  if name == 'Resnet18':\n",
        "    model = keras.models.load_model('/content/drive/My Drive/Modelos Salvos/Resnet18/resnet18-prunned-keras.h5')\n",
        "  elif name == 'AlexNet': \n",
        "    model = keras.models.load_model('/content/drive/My Drive/Modelos Salvos/AlexNet/alexnet-prunned-keras.h5')\n",
        "  elif name == 'Aluno':\n",
        "    model = keras.models.load_model('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.h5')\n",
        "  return model \n",
        "\n",
        "\n",
        "def convert_model(input_tensor, model_to_transfer):\n",
        "    \n",
        "    # define input tensor\n",
        "    input_var = Variable(torch.FloatTensor(input_tensor))\n",
        "\n",
        "    # get PyTorch model\n",
        "    model_to_transfer.eval()\n",
        "\n",
        "    # convert PyTorch model to Keras\n",
        "    model = pytorch_to_keras(\n",
        "        model_to_transfer,\n",
        "        input_var,\n",
        "        [input_var.shape[-3:]],\n",
        "        change_ordering=True,\n",
        "        verbose=False,\n",
        "        name_policy=\"keep\",\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def testeDoModelo(model, data_loader):\n",
        "  if (torch.cuda.is_available()):\n",
        "    model = model.cuda()\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_correct = 0\n",
        "  tot_predictions = []\n",
        "  labels = []\n",
        "  for batch in data_loader:\n",
        "    data , target = batch\n",
        "    if torch.cuda.is_available():\n",
        "      data,target = data.cuda(),target.cuda()\n",
        "    \n",
        "    output = model(data)\n",
        "    loss = F.cross_entropy(output,target)\n",
        "    running_loss += loss.item()\n",
        "    preds = output.data.max(dim=1,keepdim=True)[1]\n",
        "    running_correct += preds.eq(target.data.view_as(preds)).cpu().sum().item()\n",
        "    \n",
        "    tot_predictions.extend(preds.data.cpu().numpy())\n",
        "    labels.extend(target.data.cpu().numpy())\n",
        "  loss = running_loss/len(data_loader.dataset)\n",
        "  accuracy = 100. * running_correct/len(data_loader.dataset)\n",
        "  print(f'Loss is {loss:{5}.{2}} Accuracy is {running_correct}/{len(data_loader.dataset)}{accuracy:{6}.{4}}%\\n')\n",
        "  return tot_predictions, labels\n",
        "\n",
        "def metricasModelo(model, data_loader):\n",
        "  if (torch.cuda.is_available()):\n",
        "    model = model.cuda()\n",
        "    \n",
        "  print('========= Métricas do modelo ============\\n')\n",
        "  y_pred, y_test = testeDoModelo(model, data_loader)\n",
        "  target_names = ['normal', 'pneumonia']\n",
        "  print(classification_report(y_test, y_pred, target_names=target_names, digits=3))\n",
        "  print('\\n========= Confusion Matrix ============\\n')\n",
        "  confmat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[0,1])\n",
        "  fig, ax = plt.subplots(figsize=(3,3))\n",
        "  ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "  for i in range(confmat.shape[0]):\n",
        "      for j in range(confmat.shape[1]):\n",
        "          ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "  plt.xlabel('predicted label')\n",
        "  plt.ylabel('true label')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('confusion_matrix.png', dpi=300)\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMKXE39oS_RF"
      },
      "source": [
        "data_generators = preparaDadosKeras(224)\n",
        "print('Keras')\n",
        "print(data_generators['train'].class_indices)\n",
        "\n",
        "print('Pytorch')\n",
        "loaders = prepararDados(224)\n",
        "print(loaders['train'].dataset.class_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fez4DhCUAIt7"
      },
      "source": [
        "# Modelo Estudante\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XPPlJuyAKv1"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"CNN Builder.\"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "            # Conv Layer block 1\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # Conv Layer block 2\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=24, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            \n",
        "           \n",
        "        )\n",
        "        \n",
        "        self.fc_layer = nn.Sequential(\n",
        "           \n",
        "            nn.Linear(14*14*24, 2),\n",
        "       \n",
        "         \n",
        "        )\n",
        "\n",
        "    def forward(self, x):  \n",
        "\n",
        "        # conv layers\n",
        "        x = self.conv_layer(x)       \n",
        "\n",
        "        # flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # fc layer\n",
        "        x = self.fc_layer(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPZwObPMU05k"
      },
      "source": [
        "summary(Network().cuda(), (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Tq7vJEZS9cH"
      },
      "source": [
        "KERAS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmA5BrL3S83b"
      },
      "source": [
        "def get_model():\n",
        "    img_size = (224,224)\n",
        "    inputs = keras.Input(shape=(3,224,224))   \n",
        "\n",
        "    x = layers.Conv2D(16, 3, strides=1, padding=\"same\")(inputs)\n",
        "    x = layers.BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
        "\n",
        "    x = layers.Conv2D(32, 3, strides=1, padding=\"same\")(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)    \n",
        "\n",
        "    x = layers.Conv2D(32, 3, strides=1, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization(axis=1, epsilon=1e-05, momentum=0.1)(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
        "\n",
        "    x = layers.Conv2D(24, 3, strides=1, padding=\"same\")(x)\n",
        "\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
        "    \n",
        "    x = layers.Flatten(data_format='channels_last')(x)\n",
        "\n",
        "    x = layers.Dense(2)(x)\n",
        "\n",
        "    # Define the model\n",
        "    model = keras.Model(inputs, x)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atYODN4vWFFV"
      },
      "source": [
        "def get_converted_model():\n",
        "  pytorch_model = carrega_model_prunned('Aluno')\n",
        "  pytorch_model.eval()\n",
        "  params = {}\n",
        "  conv_idx = 0\n",
        "  bn_idx = 0\n",
        "  for module in pytorch_model.modules():\n",
        "    if isinstance(module, nn.Conv2d):     \n",
        "      params['conv'+str(conv_idx)] = [module.weight.data.numpy().transpose(2,3,1, 0), module.bias.data.numpy()]\n",
        "      conv_idx += 1\n",
        "\n",
        "    if isinstance(module, nn.BatchNorm2d):     \n",
        "      params['bn'+str(bn_idx)] = [module.weight.data.numpy(), module.bias.data.numpy(), module.running_mean.data.numpy(), module.running_var.data.numpy()]\n",
        "      bn_idx += 1      \n",
        "\n",
        "    if isinstance(module, nn.Linear):\n",
        "      params['linear'] = [module.weight.data.numpy().transpose(1,0), module.bias.data.numpy()]\n",
        "  keras_model = get_model()\n",
        "  conv_idx = 0\n",
        "  bn_idx = 0\n",
        "  for l in keras_model.layers: \n",
        "    if isinstance(l, layers.Conv2D):\n",
        "      l.set_weights(np.array(params['conv'+str(conv_idx)]))\n",
        "      conv_idx += 1\n",
        "\n",
        "    if isinstance(l, layers.Dense):\n",
        "      l.set_weights(np.array(params['linear']))\n",
        "\n",
        "    if isinstance(l, layers.BatchNormalization):\n",
        "      l.set_weights(np.array(params['bn'+str(bn_idx)]))\n",
        "      bn_idx += 1\n",
        "      \n",
        "  return keras_model\n",
        "\n",
        "get_converted_model().summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UllHnyqhdZeC"
      },
      "source": [
        "loaders = prepararDados(224)\n",
        "generators = preparaDadosKeras(224)\n",
        "\n",
        "pytorch_model = carrega_model_prunned('Aluno')\n",
        "pytorch_model = pytorch_model.eval()\n",
        "\n",
        "keras_model = get_converted_model()\n",
        "keras_model.save('/content/drive/My Drive/Modelos Salvos/Aluno/aluno-prunned-keras.h5')\n",
        "\n",
        "keras_corrects = 0\n",
        "pytorch_corrects = 0\n",
        "total_images = 0\n",
        "\n",
        "for batch in tqdm(loaders['test']):\n",
        "  images, labels =  batch\n",
        "  labels = labels.data.numpy()\n",
        "\n",
        "  keras_input = images.data.numpy()\n",
        "  keras_output = keras_model.predict(keras_input)\n",
        "  keras_preds = keras_output.argmax(axis=1)\n",
        "  keras_corrects += np.sum(keras_preds == labels)\n",
        "\n",
        "  pytorch_model = pytorch_model.cuda()\n",
        "  pytorch_output = pytorch_model(images.cuda()).cpu().data.numpy()\n",
        "  pytorch_preds = pytorch_output.argmax(axis=1)\n",
        "  pytorch_corrects += np.sum(pytorch_preds == labels)\n",
        "\n",
        "  total_images += len(images)\n",
        "\n",
        "  if False in np.equal(keras_preds, pytorch_preds): \n",
        "    print('KERAS PREDS DIFFERENT FROM TORCH PREDS')\n",
        "    break\n",
        "\n",
        "print('==================')\n",
        "print('KERAS ACC: ', keras_corrects/total_images)\n",
        "print('PYTORCH ACC: ', pytorch_corrects/total_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24Na01JLS4YH"
      },
      "source": [
        "generators = preparaDadosKeras(224)\n",
        "model = get_converted_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.evaluate(generators['test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_HYzi_killn"
      },
      "source": [
        "# Poda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMTyAUZ1sHF2"
      },
      "source": [
        "models_names = ['Resnet18', 'VGG', 'Densenet121', 'AlexNet', 'GoogLeNet']\n",
        "input_size = 224\n",
        "loaders = prepararDados(input_size)\n",
        "for model_name in models_names:\n",
        "  model = carrega_model(model_name)\n",
        "  acc, loss = testePruning(model, loaders['test'])\n",
        "  print(model_name+ ' - Loss: '+ str(loss)[0:5] + ' Accuracy: '+ str(acc)[0:5] +'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc3v8Rzoe87P"
      },
      "source": [
        "input_size = 224\n",
        "models_names = [ 'Resnet18', 'VGG',  'Densenet121', 'AlexNet', 'GoogLeNet']\n",
        "acc_list_models = {'Resnet18': [], 'VGG': [], 'Densenet121': [], 'AlexNet': [], 'GoogLeNet': []}\n",
        "loss_list_models = {'Resnet18': [], 'VGG': [], 'Densenet121': [], 'AlexNet': [], 'GoogLeNet': []}\n",
        "params_zerados_models = {'Resnet18': [], 'VGG': [], 'Densenet121': [], 'AlexNet': [], 'GoogLeNet': []}\n",
        "loaders = prepararDados(input_size)\n",
        "for model_name in models_names:\n",
        "  model = carrega_model(model_name) \n",
        "  pytorch_total_params = 0\n",
        "  for layer in model.modules(): \n",
        "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "      p = layer.weight.detach().numpy()\n",
        "      pytorch_total_params += p.size\n",
        "  std = calcSTD(model_name)\n",
        "  print('==================== '+model_name+' ======================')\n",
        "  print('STD: ', std)\n",
        "  frac = [2*std, std, std/2, std/4, std/6, std/6, std/10, std/12, std/14, std/16, std/18, std/20, std/25, std/30, std/35, std/40, std/45, std/50]\n",
        "\n",
        "  best_acc = 0.0\n",
        "  for f in frac: \n",
        "    # Load the original unprunned model\n",
        "    model = carrega_model(model_name)\n",
        "   \n",
        "    zeroWeights = 0   \n",
        "    # For each layer except the output one\n",
        "    for name, layer in model.named_modules():  \n",
        "      if isinstance(layer, nn.Conv2d) or (isinstance(layer, nn.Linear) and layer.out_features != 2):\n",
        "        w = layer.weight.detach().numpy()\n",
        "        w[abs(w) < f] = 0\n",
        "        layer.weight = torch.nn.Parameter(torch.tensor(w))\n",
        "        zeroWeights += np.count_nonzero(w==0)\n",
        "    \n",
        "    accuracy, loss = testePruning(model, loaders['test'])\n",
        "    if accuracy > best_acc:\n",
        "      torch.save(model.state_dict(), '/content/drive/My Drive/Modelos Salvos/'+model_name+'/'+ model_name.lower() +'-prunned.acc')\n",
        "      best_acc = accuracy\n",
        "    params_zerados_models[model_name].append(zeroWeights/pytorch_total_params)\n",
        "    acc_list_models[model_name].append(accuracy)\n",
        "    loss_list_models[model_name].append(loss)\n",
        "    print('===================================================')\n",
        "    print('Loss: '+ str(loss)[0:6] + ' Accuracy: '+ str(accuracy)[0:6] +'%')\n",
        "    print('Parâmetros zerados:', zeroWeights)\n",
        "    print('% em relação ao modelo ', str(zeroWeights/pytorch_total_params)[0:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RSSnNW1GZ4p"
      },
      "source": [
        "for model_name in models_names:\n",
        "  # plotar\n",
        "  mpl.rcParams['figure.figsize'] = (7, 4) #fig size\n",
        "  mpl.rcParams['axes.grid'] = False\n",
        "  plt.plot(params_zerados_models[model_name], acc_list_models[model_name], label=model_name)\n",
        "  plt.xlabel('Parâmetros zerados (%)')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.grid(True, which='both', axis='both')  \n",
        "  plt.tight_layout()\n",
        "  plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkk7HHEyMNDj"
      },
      "source": [
        "models_names = ['Resnet18', 'VGG', 'Densenet121', 'AlexNet', 'GoogLeNet']\n",
        "input_size = 224\n",
        "loaders = prepararDados(input_size)\n",
        "for model_name in models_names:\n",
        "  model = carrega_model_prunned(model_name)\n",
        "  acc, loss = testePruning(model, loaders['test'])\n",
        "  print(model_name+ ' - Loss: '+ str(loss)[0:5] + ' Accuracy: '+ str(acc)[0:5] +'%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSAb4ai2_L4r"
      },
      "source": [
        "|    Modelo   | Convencional | % zerada | Pruning |\n",
        "|:-----------:|:------------:|:--------:|:-------:|\n",
        "|   Resnet18  |     94.39    |   39.43   |  94.87  |\n",
        "|     VGG     |     91.35    |   87.35   |  91.35  |\n",
        "|   AlexNet   |     92.46    |   91.15   |  92.94  |\n",
        "|  GoogLeNet  |     92.62    |   24.75   |  92.78  |\n",
        "| Densenet121 |     93.10    |   23.63   |   93.26  |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWs5iSqjYl61"
      },
      "source": [
        "Poda modelo estudante (destilado) ACC do modelo podado = 90.38 com 4.01% dos parâmetros zerados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtaPSeq6Yl63"
      },
      "source": [
        "input_size = 224\n",
        "loaders = prepararDados(input_size)\n",
        "model = carregar_cnn('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno_kd_v2.acc')\n",
        "pytorch_total_params = 0\n",
        "for layer in model.modules(): \n",
        "  if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
        "    p = layer.weight.detach().numpy()\n",
        "    pytorch_total_params += p.size\n",
        "\n",
        "std = calcSTD('Aluno')\n",
        "print('==================== Aluno ======================')\n",
        "print('STD: ', std)\n",
        "frac = [2*std, std, std/2, std/4, std/6, std/6, std/10, std/12, std/14, std/16, std/18, std/20, std/25, std/30, std/35, std/40, std/45, std/50]\n",
        "\n",
        "best_acc = 0.0\n",
        "for f in frac: \n",
        "  # Load the original unprunned model\n",
        "  model = carrega_model('Aluno')\n",
        "  \n",
        "  zeroWeights = 0   \n",
        "  # For each layer except the output one\n",
        "  for name, layer in model.named_modules():  \n",
        "    if isinstance(layer, nn.Conv2d) or (isinstance(layer, nn.Linear) and layer.out_features != 2):\n",
        "      w = layer.weight.detach().numpy()\n",
        "      w[abs(w) < f] = 0\n",
        "      layer.weight = torch.nn.Parameter(torch.tensor(w))\n",
        "      zeroWeights += np.count_nonzero(w==0)\n",
        "  \n",
        "  accuracy, loss = testePruning(model, loaders['test'])\n",
        "  if accuracy > best_acc:\n",
        "    torch.save(model.state_dict(), '/content/drive/My Drive/Modelos Salvos/Aluno/'+'aluno-kd-prunned.acc')\n",
        "    best_acc = accuracy\n",
        " \n",
        "  print('===================================================')\n",
        "  print('Loss: '+ str(loss)[0:6] + ' Accuracy: '+ str(accuracy)[0:6] +'%')\n",
        "  print('Parâmetros zerados:', zeroWeights)\n",
        "  print('% em relação ao modelo ', str(zeroWeights/pytorch_total_params)[0:6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FnIR5uvfblQ"
      },
      "source": [
        "input_size = 224\n",
        "loaders = prepararDados(input_size)\n",
        "model = carregar_cnn('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned.acc')\n",
        "print('Modelo estudante destilado e podado - Test set')\n",
        "metricasModelo(model, loaders['test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0taMc8GziPa"
      },
      "source": [
        "# Pytorch to Keras Model Conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyndWMxOc_Qb"
      },
      "source": [
        "Pytorch to keras conversion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FieFeqsb84K"
      },
      "source": [
        "loaders = prepararDados(224)\n",
        "models_names = [ 'AlexNet', 'Resnet18', 'GoogLeNet', 'Densenet121', 'VGG' ]\n",
        "for model_name in models_names: \n",
        "\n",
        "  pytorch_model = carrega_model_prunned(model_name)\n",
        "  keras_model = convert_model(next(iter(loaders['test']))[0].shape, pytorch_model)\n",
        "  keras_model.save('/content/drive/My Drive/Modelos Salvos/'+model_name+'/'+model_name.lower()+'-prunned-keras.h5')\n",
        "\n",
        "  keras_corrects = 0\n",
        "  pytorch_corrects = 0\n",
        "  total_images = 0\n",
        "\n",
        "  for batch in tqdm(loaders['test']):\n",
        "    images, labels =  batch\n",
        "    labels = labels.data.numpy()\n",
        "\n",
        "    keras_input = images.data.numpy().transpose(0, 2, 3, 1)\n",
        "    keras_output = keras_model.predict(keras_input)\n",
        "    keras_preds = keras_output.argmax(axis=1)\n",
        "    keras_corrects += np.sum(keras_preds == labels)\n",
        "\n",
        "    pytorch_model = pytorch_model.cuda()\n",
        "    pytorch_output = pytorch_model(images.cuda()).cpu().data.numpy()\n",
        "    pytorch_preds = pytorch_output.argmax(axis=1)\n",
        "    pytorch_corrects += np.sum(pytorch_preds == labels)\n",
        "\n",
        "    total_images += len(images)\n",
        "\n",
        "    if False in np.equal(keras_preds, pytorch_preds): \n",
        "      print('KERAS PREDS DIFFERENT FROM TORCH PREDS')\n",
        "      break\n",
        "\n",
        "  print('==================')\n",
        "  print(model_name)\n",
        "  print('KERAS ACC: ', keras_corrects/total_images)\n",
        "  print('PYTORCH ACC: ', pytorch_corrects/total_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUoIYt46b5ME"
      },
      "source": [
        "loaders = prepararDados(224)\n",
        "models_names = [ 'AlexNet', 'Resnet18']\n",
        "for model_name in models_names: \n",
        "\n",
        "  pytorch_model = carrega_model_prunned(model_name)\n",
        "  keras_model = carrega_model_prunned_keras(model_name)\n",
        "  pytorch_model = pytorch_model.eval()\n",
        "  keras_corrects = 0\n",
        "  pytorch_corrects = 0\n",
        "  total_images = 0\n",
        "\n",
        "  for batch in tqdm(loaders['test']):\n",
        "    images, labels =  batch\n",
        "    labels = labels.data.numpy()\n",
        "\n",
        "    keras_input = images.data.numpy().transpose(0, 2, 3, 1)\n",
        "    keras_output = keras_model.predict(keras_input)\n",
        "    keras_preds = keras_output.argmax(axis=1)\n",
        "    keras_corrects += np.sum(keras_preds == labels)\n",
        "\n",
        "    pytorch_model = pytorch_model.cuda()\n",
        "    pytorch_output = pytorch_model(images.cuda()).cpu().data.numpy()\n",
        "    pytorch_preds = pytorch_output.argmax(axis=1)\n",
        "    pytorch_corrects += np.sum(pytorch_preds == labels)\n",
        "\n",
        "    total_images += len(images)\n",
        "\n",
        "    if False in np.equal(keras_preds, pytorch_preds): \n",
        "      print('KERAS PREDS DIFFERENT FROM TORCH PREDS')\n",
        "      break\n",
        "\n",
        "  print('==================')\n",
        "  print(model_name)\n",
        "  print('KERAS ACC: ', keras_corrects/total_images)\n",
        "  print('PYTORCH ACC: ', pytorch_corrects/total_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2bPMkbisxkr"
      },
      "source": [
        "# Quantização\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyFKruPwdkgg"
      },
      "source": [
        "Acurácia do modelo antes de quantizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g83yB_edb7Dj"
      },
      "source": [
        "generators = preparaDadosKeras(224)\n",
        "loaders = prepararDados(224)\n",
        "model = get_converted_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.evaluate(generators['test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFSqzgSOdnnQ"
      },
      "source": [
        "## Quantization aware training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAPeS5xVtMTP"
      },
      "source": [
        "generators = preparaDadosKeras(224)\n",
        "\n",
        "model = get_converted_model()\n",
        "\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for for quantization aware.\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# `quantize_model` requires a recompile.\n",
        "q_aware_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pleiUzBnds9i"
      },
      "source": [
        "Acurácia após quantizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdWIka2ZdsIs"
      },
      "source": [
        "acc = q_aware_model.evaluate(generators['test'])\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHSdf1Vidwsj"
      },
      "source": [
        "Fit do modelo quantizado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1GqVrNsGqbK"
      },
      "source": [
        "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath=\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-keras.h5\", monitor = 'val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "q_aware_model.fit(generators['train'], validation_data=generators['test'], epochs=25, callbacks=[checkpointer])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9NfuAAH6IIO"
      },
      "source": [
        "with tfmot.quantization.keras.quantize_scope():\n",
        "  model = keras.models.load_model('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-keras.h5')\n",
        "  q_aware_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  \n",
        "  acc = model.evaluate(generators['test'])\n",
        "  print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNj2XzconD_6"
      },
      "source": [
        "## Post training quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AhIf0buQgGd"
      },
      "source": [
        "def metricasModeloQuantizado(y_pred, y_test):\n",
        "  target_names = ['normal', 'pneumonia']\n",
        "  print(classification_report(y_test, y_pred, target_names=target_names, digits=4))\n",
        "  print('\\n========= Confusion Matrix ============\\n')\n",
        "  confmat = confusion_matrix(y_true=y_test, y_pred=y_pred, labels=[0,1])\n",
        "  fig, ax = plt.subplots(figsize=(3,3))\n",
        "  ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "  for i in range(confmat.shape[0]):\n",
        "      for j in range(confmat.shape[1]):\n",
        "          ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "  plt.xlabel('predicted label')\n",
        "  plt.ylabel('true label')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('confusion_matrix.png', dpi=300)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SU_MOE7oO7I"
      },
      "source": [
        "Convertendo pra tflite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfdUHMWdnG74"
      },
      "source": [
        "model = get_converted_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "#saving converted model in \"converted_model.tflite\" file\n",
        "open(\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJu_4rB0s7BO"
      },
      "source": [
        "TFlite model ACC = 90.38461538461539"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIJDjavhs5Ui"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite\")\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Test model on some input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "corrects = 0\n",
        "n = 0\n",
        "k = 0 \n",
        "for batch in loaders['test']:\n",
        "    images, labels =  batch\n",
        "    y = labels.data.numpy()\n",
        "    x = images.data.numpy()    \n",
        "    for i in range(len(x)): \n",
        "      input_data = np.array(x[i].reshape(input_shape),dtype=np.float32)\n",
        "      interpreter.allocate_tensors()\n",
        "      interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "      interpreter.invoke()\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      if np.argmax(output_data) == int(y[i]):\n",
        "        corrects += 1\n",
        "      n += 1\n",
        "acc = corrects/n\n",
        "print('\\n ACC =', acc*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho3wVq01oS1R"
      },
      "source": [
        "### Dynamic Range Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g17IzLZoRei"
      },
      "source": [
        "model = get_converted_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "#saving converted model in \"converted_model.tflite\" file\n",
        "open(\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-dynamic-quantized.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3TSZs00oC1c"
      },
      "source": [
        "print(\"Float model in KB:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite')/1000)\n",
        "print(\"Quantized model in KB:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-dynamic-quantized.tflite')/1000 )\n",
        "print(\"Compression ratio:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite')/os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-dynamic-quantized.tflite'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9MpZOSatXx-"
      },
      "source": [
        "Post training Dynamic Range Quantization TFlite model  ACC = 90.22435897435898"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXIBuOqUtAOd"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-dynamic-quantized.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Test model on some input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "corrects = 0\n",
        "n = 0\n",
        "tot_predictions = []\n",
        "tot_labels = []\n",
        "for batch in loaders['test']:\n",
        "    images, labels =  batch\n",
        "    y = labels.data.numpy()\n",
        "    x = images.data.numpy()\n",
        "    for i in range(len(x)): \n",
        "      input_data = x[i].reshape(input_shape)\n",
        "      interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "      interpreter.invoke()\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      if np.argmax(output_data) == int(y[i]):\n",
        "        corrects += 1\n",
        "      n += 1\n",
        "      tot_predictions.append(np.argmax(output_data))\n",
        "    tot_labels.extend(y)\n",
        "\n",
        "acc = corrects/n\n",
        "print('\\n ACC =', acc*100)\n",
        "metricasModeloQuantizado(tot_predictions, tot_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b7iAokPzgSc"
      },
      "source": [
        "### Float16 Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCpp2O0DzgSl",
        "outputId": "feaa6c86-dabb-4c4f-c309-675b331b5f1f"
      },
      "source": [
        "model = get_converted_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = converter.convert()\n",
        "#saving converted model in \"converted_model.tflite\" file\n",
        "open(\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-fp16.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt_a07xkm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpt_a07xkm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67824"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kixCOfezgSp"
      },
      "source": [
        "print(\"Float model in KB:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite')/1000)\n",
        "print(\"Quantized model in KB:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-fp16.tflite')/1000 )\n",
        "print(\"Compression ratio:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite')/os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-fp16.tflite'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xms-kuiizgSq"
      },
      "source": [
        "Post training Float16 Quantization TFlite model ACC = 90.38461538461539"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChR2etafzgSr"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-fp16.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Test model on some input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "corrects = 0\n",
        "n = 0\n",
        "tot_predictions = []\n",
        "tot_labels = []\n",
        "for batch in loaders['test']:\n",
        "    images, labels =  batch\n",
        "    y = labels.data.numpy()\n",
        "    x = images.data.numpy()\n",
        "    for i in range(len(x)): \n",
        "      input_data = x[i].reshape(input_shape)\n",
        "      interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "      interpreter.invoke()\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      if np.argmax(output_data) == int(y[i]):\n",
        "        corrects += 1\n",
        "      n += 1\n",
        "      tot_predictions.append(np.argmax(output_data))\n",
        "    tot_labels.extend(y)\n",
        "acc = corrects/n\n",
        "print('\\n ACC =', acc*100)\n",
        "metricasModeloQuantizado(tot_predictions, tot_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTOtjvAN1yeP"
      },
      "source": [
        "### Full Integer Quantization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iTLvuJx1yeQ",
        "outputId": "72d5f2ab-54bc-4b84-a989-99575ca12815"
      },
      "source": [
        "generators = preparaDadosKeras(224, bs=1)\n",
        "def representative_data_gen():\n",
        "  k = 0\n",
        "  for x,y in generators['train']:\n",
        "    k += 1\n",
        "    if k == 300: \n",
        "      break\n",
        "    yield [x]\n",
        "\n",
        "model = get_converted_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "tflite_model = converter.convert()\n",
        "#saving converted model in \"converted_model.tflite\" file\n",
        "open(\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-full-integer.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5216 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1m7kwve6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp1m7kwve6/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40704"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uF87Y6Cz1yeR"
      },
      "source": [
        "print(\"Float model in KB:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite')/1000)\n",
        "print(\"Quantized model in KB:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-full-integer.tflite')/1000 )\n",
        "print(\"Compression ratio:\", os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-keras.tflite')/os.path.getsize('/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-full-integer.tflite'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lye5pvez1yeS"
      },
      "source": [
        "Post training Full Integer Quantization TFlite model ACC = 90.86538461538461"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa5i0awH1yeS"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/Modelos Salvos/Aluno/aluno-prunned-quantized-full-integer.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "# Test model on some input data.\n",
        "input_shape = input_details[0]['shape']\n",
        "corrects = 0\n",
        "n = 0\n",
        "tot_predictions = []\n",
        "tot_labels = []\n",
        "for batch in loaders['test']:\n",
        "    images, labels =  batch\n",
        "    y = labels.data.numpy()\n",
        "    x = images.data.numpy()\n",
        "    for i in range(len(x)): \n",
        "      input_data = x[i].reshape(input_shape)\n",
        "      interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "      interpreter.invoke()\n",
        "      output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "      if np.argmax(output_data) == int(y[i]):\n",
        "        corrects += 1\n",
        "      n += 1\n",
        "      tot_predictions.append(np.argmax(output_data))\n",
        "    tot_labels.extend(y)\n",
        "acc = corrects/n\n",
        "print('\\n ACC =', acc*100)\n",
        "metricasModeloQuantizado(tot_predictions, tot_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}